{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junghoum/Hello-world/blob/main/N432/N432a_Beyond_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76fedf43",
      "metadata": {
        "id": "76fedf43"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## *AIB / SECTION 4 / SPRINT 3 / NOTE 2*\n",
        "\n",
        "---\n",
        "\n",
        "# N432. Beyond Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c0ce2a6",
      "metadata": {
        "id": "1c0ce2a6"
      },
      "source": [
        "## 문제1.\n",
        "Lecture Note에 구성되어 있는 U-Net모델에서 baseline 모델을 MobilenetV2가 아닌 Vgg16을 사용하겠습니다.\n",
        "\n",
        "또한, 업샘플러 부분을 pix2pix가 아닌 직접,Conv2DTranspose를 사용해 구현하고 Sequential API가 아닌 함수형 API를 이용해보겠습니다.\n",
        "\n",
        "U-Net을 구성하기 위해서는 vgg16 모델에서 다운샘플링할 때 꺼내온 5개의 레이어와 업샘플링할 때 레이어의 결과값의 형태가 같아야 합니다.\n",
        "\n",
        "U-Net을 구성하기 위해 알맞은 A, B, C, D를 입력하세요.\n",
        "- [100, 100, 100, 100] 형태로 입력하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c61d2a2f",
      "metadata": {
        "id": "c61d2a2f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c4498487",
      "metadata": {
        "id": "c4498487"
      },
      "outputs": [],
      "source": [
        "img_shape = (128, 128, 3)\n",
        "base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False)\n",
        "down_stack=tf.keras.Model(inputs=[base_model.input],\n",
        "                       outputs=[\n",
        "                                base_model.get_layer(name='block5_conv3').output,\n",
        "                                base_model.get_layer(name='block4_conv3').output,\n",
        "                                base_model.get_layer(name='block3_conv3').output,\n",
        "                                base_model.get_layer(name='block2_conv2').output,\n",
        "                                base_model.get_layer(name='block1_conv2').output\n",
        "])\n",
        "\n",
        "down_stack.trainable = False\n",
        "\n",
        "i=tf.keras.Input(shape=img_shape)\n",
        "\n",
        "out, out1, out2, out3, out4 = down_stack(i)\n",
        "\n",
        "A = 512\n",
        "B = 256\n",
        "C = 128\n",
        "D = 64\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(A, 3,strides=2,padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out,out1])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(B, 3,strides=2,padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out,out2])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(C, 3,strides=2,padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out,out3])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(D, 3,strides=2,padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out,out4])\n",
        "\n",
        "out = tf.keras.layers.Conv2D(3, 3, activation='elu', padding='same') (out)\n",
        "out = tf.keras.layers.Dense(3,activation='softmax')(out)\n",
        "\n",
        "unet_model = tf.keras.Model(inputs=[i], outputs=[out])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NMz2X_XiQkH7"
      },
      "id": "NMz2X_XiQkH7",
      "execution_count": 2,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "N432a_Beyond_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}